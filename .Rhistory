imagenNew$areas[2]
imagenNew$areas[1]
source_python("functions.py", convert = TRUE)
threshold(imagenNew, thr)
#Crear instancia clase imagen
imagenNew <- Imagen(NULL)
imagenNew$image <- "./images/mini.jpg"
imagenNew$set_NUM(10)
#leer imagen en R directamente
imagenR <- readImage(imagenNew$image )
EBImage::display(imagenR, method = "raster")
#Imagen from python
cargarImagen(imagenNew, imagenNew$image)
imgR <- py_2_R_imageColor(imagenNew$imageRGB)
display(imgR, method = "raster")
# definir puntos de entrenamiento
va <- locator(n = imagenNew$NUM, type = "p")
nova <- locator(n = imagenNew$NUM, type = "p")
library(xaringan)
vac <- featureCoord(va)
novac <- featureCoord(nova)
vac <- unname(vac)
vac <- r_to_py(vac, convert = FALSE)
novac <- unname(novac)
novac <- r_to_py(novac)
## asignar puntos a objeto
imagenNew$set_xy(vac, novac)
#generar vector de caracteristicas
fvp = computeFeatureVector(imagenNew)
#crear clasificador
clf = trainKnn(imagenNew)
#Clasificar imagen
B = classImage(imagenNew)
imagenNew$B = B
#visualizar la clasificacion
BR <- py_2_R_imageBW(B)
display(BR, method = "raster")
#Crear etiquetas/watersheed/medirAreas
statistics(imagenNew)
#Thresholding
thr = 2000 # se pasará por según valor deslizador
threshold(imagenNew, thr)
imagenNew$ratio
imagenNew$bigAreaSum
10000/100
100/10000
10000*0.5
100*0.5
50/5000
100/9
100*0.5
9*0.5
50/4.5
runApp()
runApp()
runApp()
runApp()
runApp()
imagenNew$bigRange
2134*0.2^2
imagenNew$bigRange[[1]]
runApp()
runApp()
runApp()
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
uploadImage$ok
uploadImage$ok
runApp()
runApp()
runApp()
shiny::runApp()
runApp()
runApp()
runApp()
##OJO antes de ejecutar esto hay que activar el entorno virtual
## source ~/env/Rython/bin/activate
Sys.setenv(RETICULATE_PYTHON="/home/fpsanz/Rython/bin/python3")
library(reticulate)
library(tidyverse)
library(EBImage)
source_python("functions.py", convert = TRUE)
search()
grepl("package:reticulate" ,search())
any(grepl("package:reticulate" ,search()))
if( any(grepl("package:reticulate" ,search()))){detach("package:reticulate")}
shiny::runApp()
runApp()
source_python("functions.py", convert = TRUE)
#Crear instancia clase imagen
imagenNew <- Imagen(NULL)
imagenNew$image <- "./images/mini.jpg"
imagenNew$set_NUM(10)
#leer imagen en R directamente
imagenR <- readImage(imagenNew$image )
EBImage::display(imagenR, method = "raster")
#Imagen from python
cargarImagen(imagenNew, imagenNew$image)
imgR <- py_2_R_imageColor(imagenNew$imageRGB)
display(imgR, method = "raster")
# definir puntos de entrenamiento
va <- locator(n = imagenNew$NUM, type = "p")
nova <- locator(n = imagenNew$NUM, type = "p")
vac <- featureCoord(va)
novac <- featureCoord(nova)
vac <- unname(vac)
vac <- r_to_py(vac, convert = FALSE)
novac <- unname(novac)
novac <- r_to_py(novac)
## asignar puntos a objeto
imagenNew$set_xy(vac, novac)
#generar vector de caracteristicas
fvp = computeFeatureVector(imagenNew)
fvp2 = py_eval("fvp = imagen.fvp")
fvp2 = py_eval(fvp = imagen.fvp)
fvp2 = py_eval(imagen.fvp)
imagen = py_eval(imagen=imagenNew)
imagen = py_eval("imagen=imagenNew")
#crear clasificador
clf = trainKnn(imagenNew)
clf = trainSVM(imagenNew)
source("utils.R")
#reticulate::use_python("/home/fpsanz/Rython/bin/python3", required = FALSE)
#reticulate::use_virtualenv("/home/fpsanz/Rython")
source_python("functions.py", convert = TRUE)
clf = trainSVM(imagenNew)
source_python("functions.py", convert = TRUE)
clf = trainSVM(imagenNew)
source_python("functions.py", convert = TRUE)
clf = trainSVM(imagenNew)
imagenNew$NUM
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
counter
counter =1
runApp()
shiny::runApp()
va$x
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
#Crear instancia clase imagen
imagenNew <- Imagen(NULL)
imagenNew$image <- "./images/01_X100.tif"
imagenNew$set_NUM(10)
#leer imagen en R directamente
imagenR <- readImage(imagenNew$image )
EBImage::display(imagenR, method = "raster")
##OJO antes de ejecutar esto hay que activar el entorno virtual
## source ~/env/Rython/bin/activate
if( any(grepl("package:reticulate" ,search()))){detach("package:reticulate")}
Sys.setenv(RETICULATE_PYTHON="/home/fpsanz/Rython/bin/python3")
library(reticulate)
library(tidyverse)
library(EBImage)
#reticulate::use_virtualenv("~/.virtualenvs/Rython/")
#use_python("/usr/bin/python3")
source_python("functions.py", convert = TRUE)
#Crear instancia clase imagen
imagenNew <- Imagen(NULL)
imagenNew$image <- "./images/01_X100.tif"
imagenNew$set_NUM(10)
#leer imagen en R directamente
imagenR <- readImage(imagenNew$image )
EBImage::display(imagenR, method = "raster")
shiny::runApp()
0.454/2
/2
0.454/2/2
runApp()
input$pixelsize
as.numeric(input$pixelsize)
runApp()
runApp()
runApp()
##OJO antes de ejecutar esto hay que activar el entorno virtual
## source ~/env/Rython/bin/activate
if( any(grepl("package:reticulate" ,search()))){detach("package:reticulate")}
Sys.setenv(RETICULATE_PYTHON="/home/fpsanz/Rython/bin/python3")
library(reticulate)
library(tidyverse)
library(EBImage)
#reticulate::use_virtualenv("~/.virtualenvs/Rython/")
#use_python("/usr/bin/python3")
source_python("functions.py", convert = TRUE)
#Crear instancia clase imagen
imagenNew <- Imagen(NULL)
imagenNew$image <- "./images/01_X100.tif"
imagenNew$set_NUM(10)
#leer imagen en R directamente
imagenR <- readImage(imagenNew$image )
EBImage::display(imagenR, method = "raster")
#Imagen from python
cargarImagen(imagenNew, imagenNew$image)
imagenNew$image <- "./images/01_X100_05.jpg"
imagenNew$set_NUM(10)
#leer imagen en R directamente
imagenR <- readImage(imagenNew$image )
EBImage::display(imagenR, method = "raster")
#Imagen from python
cargarImagen(imagenNew, imagenNew$image)
imgR <- py_2_R_imageColor(imagenNew$imageRGB)
#reticulate::use_virtualenv("~/.virtualenvs/Rython/")
#use_python("/usr/bin/python3")
source_python("functions.py", convert = TRUE)
imgR <- py_2_R_imageColor(imagenNew$imageRGB)
source("utils.R")
imgR <- py_2_R_imageColor(imagenNew$imageRGB)
display(imgR, method = "raster")
# definir puntos de entrenamiento
va <- locator(n = imagenNew$NUM, type = "p")
nova <- locator(n = imagenNew$NUM, type = "p")
vac <- featureCoord(va)
novac <- featureCoord(nova)
vac <- unname(vac)
vac <- r_to_py(vac, convert = FALSE)
novac <- unname(novac)
novac <- r_to_py(novac)
## asignar puntos a objeto
imagenNew$set_xy(vac, novac)
#generar vector de caracteristicas
fvp = computeFeatureVector(imagenNew)
shiny::runApp()
runApp()
runApp()
shiny::runApp()
runApp()
runApp()
source("utils.R")
runApp()
runApp()
#reticulate::use_python("/home/fpsanz/Rython/bin/python3", required = FALSE)
#reticulate::use_virtualenv("/home/fpsanz/Rython")
source_python("functions.py", convert = TRUE)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
shiny::runApp()
runApp()
shiny::runApp()
runApp()
##OJO antes de ejecutar esto hay que activar el entorno virtual
## source ~/env/Rython/bin/activate
if( any(grepl("package:reticulate" ,search()))){detach("package:reticulate")}
Sys.setenv(RETICULATE_PYTHON="/home/fpsanz/Rython/bin/python3")
library(reticulate)
library(tidyverse)
library(EBImage)
#reticulate::use_virtualenv("~/.virtualenvs/Rython/")
#use_python("/usr/bin/python3")
source_python("functions.py", convert = TRUE)
source("utils.R")
#Crear instancia clase imagen
imagenNew <- Imagen(NULL)
imagenNew$image <- "./images/01_X100_05.jpg"
imagenNew$set_NUM(10)
#leer imagen en R directamente
imagenR <- readImage(imagenNew$image )
EBImage::display(imagenR, method = "raster")
#Imagen from python
cargarImagen(imagenNew, imagenNew$image)
imgR <- py_2_R_imageColor(imagenNew$imageRGB)
display(imgR, method = "raster")
#load model
imagenNew$clf = loadModel(filepath$datapath)
#load model
imagenNew$clf = loadModel("/datos/repos/visionGUI/knnModel")
imagenNew$clf
B = classModel(imagenNew, imagenNew$clf)
#reticulate::use_virtualenv("~/.virtualenvs/Rython/")
#use_python("/usr/bin/python3")
source_python("functions.py", convert = TRUE)
source("utils.R")
#Crear instancia clase imagen
imagenNew <- Imagen(NULL)
imagenNew$image <- "./images/01_X100_05.jpg"
imagenNew$set_NUM(10)
#load model
imagenNew$clf = loadModel("/datos/repos/visionGUI/knnModel")
B = classModel(imagenNew, imagenNew$clf)
B = classModel(imagenNew)
im = np.dstack((imagen.imageRGB, imagen.imageCIE))
imagen = imagenNew
im = np.dstack((imagen.imageRGB, imagen.imageCIE))
#load model
imagenNew$clf = loadModel("/datos/repos/visionGUI/knnModel")
imagen = imagenNew
imagen.imageRGB
#Clasificar imagen
B = classImage(imagenNew)
##OJO antes de ejecutar esto hay que activar el entorno virtual
## source ~/env/Rython/bin/activate
if( any(grepl("package:reticulate" ,search()))){detach("package:reticulate")}
Sys.setenv(RETICULATE_PYTHON="/home/fpsanz/Rython/bin/python3")
library(reticulate)
library(tidyverse)
library(EBImage)
#reticulate::use_virtualenv("~/.virtualenvs/Rython/")
#use_python("/usr/bin/python3")
source_python("functions.py", convert = TRUE)
source("utils.R")
#Crear instancia clase imagen
imagenNew <- Imagen(NULL)
imagenNew$image <- "./images/01_X100_05.jpg"
imagenNew$set_NUM(10)
#leer imagen en R directamente
imagenR <- readImage(imagenNew$image )
EBImage::display(imagenR, method = "raster")
#Imagen from python
cargarImagen(imagenNew, imagenNew$image)
imgR <- py_2_R_imageColor(imagenNew$imageRGB)
display(imgR, method = "raster")
#load model
imagenNew$clf = loadModel("/datos/repos/visionGUI/knnModel")
imagen = imagenNew
imagen.imageRGB
imagen.imagenRGB
imagen.clf
im = np.dstack( (imagen.imageRGB, imagen.imageCIE) )
im = np.reshape(im, ((imagen.imageRGB.shape[0] * imagen.imageRGB.shape[1]), 6))
im = np.dstack( (imagen.imageRGB, imagen.imageCIE) )
runApp()
#Crear instancia clase imagen
imagenNew <- Imagen(NULL)
imagenNew$image <- "./images/01_X100.jpg"
imagenNew$set_NUM(10)
#leer imagen en R directamente
imagenR <- readImage(imagenNew$image )
EBImage::display(imagenR, method = "raster")
EBImage::display(imagenR, method = "raster")
#Imagen from python
cargarImagen(imagenNew, imagenNew$image)
imgR <- py_2_R_imageColor(imagenNew$imageRGB)
display(imgR, method = "raster")
display(imgR, method = "raster")
runApp()
runApp()
runApp()
shiny::runApp()
runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
shiny::runApp()
runApp()
runApp()
library(shiny)
library(shinydashboard)
library(shinyalert)
library(shinyBS)
library(shinyWidgets)
library(shinydashboardPlus)
library(shinyjs)
library(shinythemes)
library(reticulate)
library(tidyverse)
library(ShinyImage)
library(EBImage)
library(DiagrammeR)
library(png)
library(shinyFiles)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
shinyFilesExample()
runApp('/datos/repos/Rython')
shinyFilesExample()
runApp()
shinyFilesExample()
runApp()
runApp()
runApp()
pathDir
pathDir()
is.null(pathDir())
pathDir()
pathDir()
runApp()
page
page
runApp()
runApp()
runApp()
runApp()
page <- paste0("<html>
<head>
<title>TODO supply a title</title>
<meta charset='UTF-8'>
<meta name='viewport' content='width=device-width, initial-scale=1.0'>
<link rel='stylesheet'
type='text/css'
media='screen'
href='https://openseadragon.github.io/css/style.css'/>
<script src='openseadragon/openseadragon.min.js'></script>
<script src='Openseadragon-screenshot-master/openseadragonScreenshot.min.js'></script>
<script src='Openseadragon-screenshot-master/FileSaver.js'></script>
<script src='Openseadragon-screenshot-master/canvas-toBlob.js'></script>
<script src='openseadragonselection-master/dist/openseadragonselection.js'></script>
<style>
#container {
width: 100% !important;
}
</style>
</head>
<body>
<div class='demoarea'>
<div id='toolbarDiv' style='width: 100%; height: 50px;'>
</div>
<div id='example-inline-configuration-for-zoomify'
style='width: 1200px; height: 600px;'>
</div>
</div>
<script type='text/javascript'>
var viewer = OpenSeadragon({
id: 'example-inline-configuration-for-zoomify',
showNavigator: true,
navigatorPosition: 'TOP_RIGHT',
showFlipControl: true,
showRotationControl: true,
SequenceMode: true,
ShowSequenceControl: true,
crossOriginPolicy: 'Anonymous',
toolbar: 'toolbarDiv',
tileSources: [{
type: 'zoomifytileservice',
width: 205176,
height: 90559,
tilesUrl: './SL14B0004838-A-8-1'
}]
});
viewer.screenshot({
showOptions: true
});
</script>
</body>
</html>")
page
runApp()
runApp()
runApp()
runApp()
